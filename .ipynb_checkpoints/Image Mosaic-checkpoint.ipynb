{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd                 \n",
    "import numpy as np                                       \n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "import cv2                         # To read and manipulate images\n",
    "import os                          # For filepath, directory handling\n",
    "import sys                         # System-specific parameters and functions\n",
    "import tqdm                        # Use smart progress meter\n",
    "import seaborn as sns              # For pairplots\n",
    "import matplotlib.pyplot as plt    # Python 2D plotting library\n",
    "import matplotlib.cm as cm         # Color map\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DIR = workspace/dsb2018/data/kaggle-dsbowl-2018-dataset-fixes-master/stage1_train\n",
      "TEST_DIR = workspace/dsb2018/data/kaggle-dsbowl-2018-dataset-fixes-master/stage1_test\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'workspace/dsb2018/data/kaggle-dsbowl-2018-dataset-fixes-master/stage1_train'\n",
    "TEST_DIR = 'workspace/dsb2018/data/kaggle-dsbowl-2018-dataset-fixes-master/stage1_test'\n",
    "IMG_DIR_NAME = 'images'   # Folder name including the image\n",
    "MASK_DIR_NAME = 'masks'   # Folder name including the masks\n",
    "    \n",
    "\n",
    "# Display working/train/test directories.\n",
    "print('TRAIN_DIR = {}'.format(TRAIN_DIR))\n",
    "print('TEST_DIR = {}'.format(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collection of methods for data operations. Implemented are functions to read  \n",
    "# images/masks from files and to read basic properties of the train/test data sets.\n",
    "\n",
    "def read_image(filepath, color_mode=cv2.IMREAD_COLOR, target_size=None, space='bgr'):\n",
    "    \"\"\"Read an image from a file and resize it.\"\"\"\n",
    "    img = cv2.imread(filepath, color_mode)\n",
    "    if target_size: \n",
    "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n",
    "    if space == 'hsv':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return img\n",
    "\n",
    "def read_train_data_properties(train_dir, img_dir_name, mask_dir_name):\n",
    "    \"\"\"Read basic properties of training images and masks\"\"\"\n",
    "    tmp = []\n",
    "    for i,dir_name in enumerate(next(os.walk(train_dir))[1]):\n",
    "\n",
    "        img_dir = os.path.join(train_dir, dir_name, img_dir_name)\n",
    "        mask_dir = os.path.join(train_dir, dir_name, mask_dir_name) \n",
    "        num_masks = len(next(os.walk(mask_dir))[2])\n",
    "        img_name = next(os.walk(img_dir))[2][0]\n",
    "        img_name_id = os.path.splitext(img_name)[0]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        mask_path = os.path.join(train_dir,dir_name,FULL_MASK_DIR_NAME,img_name_id+'_mask.png')\n",
    "        img_shape = read_image(img_path).shape\n",
    "        tmp.append(['{}'.format(img_name_id), img_shape[0], img_shape[1],\n",
    "                    img_shape[0]/img_shape[1], img_shape[2], num_masks,\n",
    "                    img_path, mask_dir,mask_path])\n",
    "\n",
    "    train_df = pd.DataFrame(tmp, columns = ['img_id', 'img_height', 'img_width',\n",
    "                                            'img_ratio', 'num_channels', \n",
    "                                            'num_masks', 'image_path', 'mask_dir','mask_path'])\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def read_test_data_properties(test_dir, img_dir_name):\n",
    "    \"\"\"Read basic properties of test images.\"\"\"\n",
    "    tmp = []\n",
    "    for i,dir_name in enumerate(next(os.walk(test_dir))[1]):\n",
    "\n",
    "        img_dir = os.path.join(test_dir, dir_name, img_dir_name)\n",
    "        img_name = next(os.walk(img_dir))[2][0]\n",
    "        img_name_id = os.path.splitext(img_name)[0]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img_shape = read_image(img_path).shape\n",
    "        tmp.append(['{}'.format(img_name_id), img_shape[0], img_shape[1],\n",
    "                    img_shape[0]/img_shape[1], img_shape[2], img_path])\n",
    "\n",
    "    test_df = pd.DataFrame(tmp, columns = ['img_id', 'img_height', 'img_width',\n",
    "                                           'img_ratio', 'num_channels', 'image_path'])\n",
    "    return test_df\n",
    "\n",
    "def load_raw_data(image_size=(256, 256), space = 'bgr',load_mask=True):\n",
    "    \"\"\"Load raw data.\"\"\"\n",
    "    # Python lists to store the training images/masks and test images.\n",
    "    x_train, y_train, x_test = [],[],[]\n",
    "\n",
    "    # Read and resize train images/masks. \n",
    "    print('Loading and resizing train images and masks ...')\n",
    "    sys.stdout.flush()\n",
    "    for i, filename in tqdm.tqdm(enumerate(train_df['image_path']), total=len(train_df)):\n",
    "        img = read_image(train_df['image_path'].loc[i], target_size=image_size,space = space)\n",
    "        if load_mask:\n",
    "            mask = read_image(train_df['mask_path'].loc[i],\n",
    "                              color_mode=cv2.IMREAD_GRAYSCALE,\n",
    "                              target_size=image_size)\n",
    "            #mask = read_mask(train_df['mask_dir'].loc[i], target_size=image_size)\n",
    "            y_train.append(mask)\n",
    "        x_train.append(img)\n",
    "        \n",
    "    # Read and resize test images. \n",
    "    print('Loading and resizing test images ...')\n",
    "    sys.stdout.flush()\n",
    "    for i, filename in tqdm.tqdm(enumerate(test_df['image_path']), total=len(test_df)):\n",
    "        img = read_image(test_df['image_path'].loc[i], target_size=image_size,space=space)\n",
    "        x_test.append(img)\n",
    "\n",
    "    # Transform lists into 4-dim numpy arrays.\n",
    "    x_train = np.array(x_train)\n",
    "    #if load_mask:\n",
    "    y_train = np.array(y_train)\n",
    "    #y_train = np.expand_dims(np.array(y_train), axis=4)\n",
    "    x_test = np.array(x_test)\n",
    "    print('Data loaded')\n",
    "    if load_mask:\n",
    "        return x_train, y_train, x_test\n",
    "    else:\n",
    "        return x_train, x_test\n",
    "\n",
    "def get_domimant_colors(img, top_colors=1):\n",
    "    \"\"\"Return dominant image color\"\"\"\n",
    "    img_l = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n",
    "    clt = KMeans(n_clusters = top_colors)\n",
    "    clt.fit(img_l)\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return clt.cluster_centers_, hist\n",
    "\n",
    "def cluster_images_by_hsv():\n",
    "    \"\"\"Clusterization based on hsv colors. Adds 'hsv_cluster' column to tables\"\"\"\n",
    "    print('Loading data')\n",
    "    x_train_hsv,x_test_hsv = load_raw_data(image_size=None,space='hsv',load_mask=False)\n",
    "    x_hsv = np.concatenate([x_train_hsv,x_test_hsv])\n",
    "    print('Calculating dominant hsv for each image')\n",
    "    dominant_hsv = []\n",
    "    for img in tqdm.tqdm(x_hsv):\n",
    "        res1, res2 = get_domimant_colors(img,top_colors=1)\n",
    "        dominant_hsv.append(res1.squeeze())\n",
    "    print('Calculating clusters')\n",
    "    kmeans = KMeans(n_clusters=3).fit(dominant_hsv)\n",
    "    train_df['HSV_CLUSTER'] = kmeans.predict(dominant_hsv[:len(x_train_hsv)])\n",
    "    test_df['HSV_CLUSTER'] = kmeans.predict(dominant_hsv[len(x_train_hsv):])\n",
    "    print('Images clustered')\n",
    "    return None\n",
    "\n",
    "def plot_images(selected_images_df,images_rows=4,images_cols=8,plot_figsize=4):\n",
    "    \"\"\"Plot image_rows*image_cols of selected images. Used to visualy check clusterization\"\"\"\n",
    "    f, axarr = plt.subplots(images_rows,images_cols,figsize=(plot_figsize*images_cols,images_rows*plot_figsize))\n",
    "    for row in range(images_rows):\n",
    "        for col in range(images_cols):\n",
    "            if (row*images_cols + col) < selected_images_df.shape[0]:\n",
    "                image_path = selected_images_df['image_path'].iloc[row*images_cols + col]\n",
    "            else:\n",
    "                continue\n",
    "            img = read_image(image_path)\n",
    "            height, width, l = img.shape\n",
    "            ax = axarr[row,col]\n",
    "            ax.axis('off')\n",
    "            ax.set_title(\"%dx%d\"%(width, height))\n",
    "            ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
